{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6tasuafvT2O"
   },
   "source": [
    "# Deep Fake Detection using CNN and RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:24:20.170467Z",
     "iopub.status.busy": "2024-09-16T09:24:20.16971Z",
     "iopub.status.idle": "2024-09-16T09:26:07.157951Z",
     "shell.execute_reply": "2024-09-16T09:26:07.156728Z",
     "shell.execute_reply.started": "2024-09-16T09:24:20.170426Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -U --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:26:07.160554Z",
     "iopub.status.busy": "2024-09-16T09:26:07.160197Z",
     "iopub.status.idle": "2024-09-16T09:26:18.58608Z",
     "shell.execute_reply": "2024-09-16T09:26:18.585047Z",
     "shell.execute_reply.started": "2024-09-16T09:26:07.160513Z"
    },
    "id": "TFSU3FCOpKzu"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:26:18.588081Z",
     "iopub.status.busy": "2024-09-16T09:26:18.587498Z",
     "iopub.status.idle": "2024-09-16T09:26:19.272424Z",
     "shell.execute_reply": "2024-09-16T09:26:19.271381Z",
     "shell.execute_reply.started": "2024-09-16T09:26:18.588041Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:26:19.274177Z",
     "iopub.status.busy": "2024-09-16T09:26:19.273797Z",
     "iopub.status.idle": "2024-09-16T09:26:19.282679Z",
     "shell.execute_reply": "2024-09-16T09:26:19.281607Z",
     "shell.execute_reply.started": "2024-09-16T09:26:19.27414Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:26:19.286219Z",
     "iopub.status.busy": "2024-09-16T09:26:19.285862Z",
     "iopub.status.idle": "2024-09-16T09:26:19.294676Z",
     "shell.execute_reply": "2024-09-16T09:26:19.293905Z",
     "shell.execute_reply.started": "2024-09-16T09:26:19.286167Z"
    },
    "id": "8d4TH3NbpKzx"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rc('font', size=14)\n",
    "plt.rc('axes', labelsize=14, titlesize=14)\n",
    "plt.rc('legend', fontsize=14)\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('ytick', labelsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NL3Ht4wC9b3n"
   },
   "source": [
    "## Data Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:26:19.296243Z",
     "iopub.status.busy": "2024-09-16T09:26:19.29588Z",
     "iopub.status.idle": "2024-09-16T09:26:19.306608Z",
     "shell.execute_reply": "2024-09-16T09:26:19.30583Z",
     "shell.execute_reply.started": "2024-09-16T09:26:19.296199Z"
    },
    "id": "jfv9PxSB4tM8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_data():\n",
    "    return pd.read_csv('../input/deepfake-faces/metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:26:19.30798Z",
     "iopub.status.busy": "2024-09-16T09:26:19.30771Z",
     "iopub.status.idle": "2024-09-16T09:26:19.557215Z",
     "shell.execute_reply": "2024-09-16T09:26:19.556234Z",
     "shell.execute_reply.started": "2024-09-16T09:26:19.307951Z"
    },
    "id": "tDW7BRph9ehF",
    "outputId": "97de18b5-0a37-4302-8804-8a16a7d2ed2f"
   },
   "outputs": [],
   "source": [
    "meta=get_data()\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:26:19.558663Z",
     "iopub.status.busy": "2024-09-16T09:26:19.558378Z",
     "iopub.status.idle": "2024-09-16T09:26:19.56577Z",
     "shell.execute_reply": "2024-09-16T09:26:19.56486Z",
     "shell.execute_reply.started": "2024-09-16T09:26:19.558632Z"
    },
    "id": "n7FSdDifbZxn",
    "outputId": "5451a127-405a-4c0b-a197-c920b796adbb"
   },
   "outputs": [],
   "source": [
    "meta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:26:19.567538Z",
     "iopub.status.busy": "2024-09-16T09:26:19.567074Z",
     "iopub.status.idle": "2024-09-16T09:26:19.625006Z",
     "shell.execute_reply": "2024-09-16T09:26:19.624072Z",
     "shell.execute_reply.started": "2024-09-16T09:26:19.567502Z"
    },
    "id": "_FJcz2IthxVG",
    "outputId": "274c3f65-7acb-4f99-8aa9-a5b2a23bf06a"
   },
   "outputs": [],
   "source": [
    "len(meta[meta.label=='FAKE']),len(meta[meta.label=='REAL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:26:19.626503Z",
     "iopub.status.busy": "2024-09-16T09:26:19.626151Z",
     "iopub.status.idle": "2024-09-16T09:26:19.68547Z",
     "shell.execute_reply": "2024-09-16T09:26:19.684667Z",
     "shell.execute_reply.started": "2024-09-16T09:26:19.626469Z"
    },
    "id": "IgMfzY-PjjtH"
   },
   "outputs": [],
   "source": [
    "real_df = meta[meta[\"label\"] == \"REAL\"]\n",
    "fake_df = meta[meta[\"label\"] == \"FAKE\"]\n",
    "sample_size = 8000\n",
    "\n",
    "real_df = real_df.sample(sample_size, random_state=42)\n",
    "fake_df = fake_df.sample(sample_size, random_state=42)\n",
    "\n",
    "sample_meta = pd.concat([real_df, fake_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned instead of using 95k images we will only use 16000 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:26:19.687161Z",
     "iopub.status.busy": "2024-09-16T09:26:19.68676Z",
     "iopub.status.idle": "2024-09-16T09:26:19.954399Z",
     "shell.execute_reply": "2024-09-16T09:26:19.953478Z",
     "shell.execute_reply.started": "2024-09-16T09:26:19.687116Z"
    },
    "id": "5eB86S6K-T5Z"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Train_set, Test_set = train_test_split(sample_meta,test_size=0.2,random_state=42,stratify=sample_meta['label'])\n",
    "Train_set, Val_set  = train_test_split(Train_set,test_size=0.3,random_state=42,stratify=Train_set['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:26:19.956063Z",
     "iopub.status.busy": "2024-09-16T09:26:19.955709Z",
     "iopub.status.idle": "2024-09-16T09:26:19.962935Z",
     "shell.execute_reply": "2024-09-16T09:26:19.961927Z",
     "shell.execute_reply.started": "2024-09-16T09:26:19.956027Z"
    },
    "id": "8p-TONijb4qA",
    "outputId": "56d0b529-9d81-4019-d8fa-618c8cdba90f"
   },
   "outputs": [],
   "source": [
    "Train_set.shape,Val_set.shape,Test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:26:19.96584Z",
     "iopub.status.busy": "2024-09-16T09:26:19.964749Z",
     "iopub.status.idle": "2024-09-16T09:26:22.365994Z",
     "shell.execute_reply": "2024-09-16T09:26:22.365039Z",
     "shell.execute_reply.started": "2024-09-16T09:26:19.96578Z"
    },
    "id": "hzNGtCWd-mTk",
    "outputId": "5178c3ed-cbba-4f99-99d0-26bde11a5dab"
   },
   "outputs": [],
   "source": [
    "y = dict()\n",
    "\n",
    "y[0] = []\n",
    "y[1] = []\n",
    "\n",
    "for set_name in (np.array(Train_set['label']), np.array(Val_set['label']), np.array(Test_set['label'])):\n",
    "    y[0].append(np.sum(set_name == 'REAL'))\n",
    "    y[1].append(np.sum(set_name == 'FAKE'))\n",
    "\n",
    "trace0 = go.Bar(\n",
    "    x=['Train Set', 'Validation Set', 'Test Set'],\n",
    "    y=y[0],\n",
    "    name='REAL',\n",
    "    marker=dict(color='#33cc33'),\n",
    "    opacity=0.7\n",
    ")\n",
    "trace1 = go.Bar(\n",
    "    x=['Train Set', 'Validation Set', 'Test Set'],\n",
    "    y=y[1],\n",
    "    name='FAKE',\n",
    "    marker=dict(color='#ff3300'),\n",
    "    opacity=0.7\n",
    ")\n",
    "\n",
    "data = [trace0, trace1]\n",
    "layout = go.Layout(\n",
    "    title='Count of classes in each set',\n",
    "    xaxis={'title': 'Set'},\n",
    "    yaxis={'title': 'Count'}\n",
    ")\n",
    "\n",
    "fig = go.Figure(data, layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original image dataset were biased with more fake images than real since we are taking a sample of it its better to take equal proportion of real and fake images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:26:22.372335Z",
     "iopub.status.busy": "2024-09-16T09:26:22.371834Z",
     "iopub.status.idle": "2024-09-16T09:26:24.771019Z",
     "shell.execute_reply": "2024-09-16T09:26:24.769712Z",
     "shell.execute_reply.started": "2024-09-16T09:26:22.372296Z"
    },
    "id": "VR7Uly2fcUYi",
    "outputId": "c1f47a82-ef4f-4bcd-b51c-d4738142fc0f"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "for cur,i in enumerate(Train_set.index[25:50]):\n",
    "    plt.subplot(5,5,cur+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    \n",
    "    plt.imshow(cv2.imread('../input/deepfake-faces/faces_224/'+Train_set.loc[i,'videoname'][:-4]+'.jpg'))\n",
    "    \n",
    "    if(Train_set.loc[i,'label']=='FAKE'):\n",
    "        plt.xlabel('FAKE Image')\n",
    "    else:\n",
    "        plt.xlabel('REAL Image')\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOvN_divkl-N"
   },
   "source": [
    "# Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oid44Xx-pKz6"
   },
   "source": [
    "### Custom CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:26:24.772474Z",
     "iopub.status.busy": "2024-09-16T09:26:24.772135Z",
     "iopub.status.idle": "2024-09-16T09:26:24.77935Z",
     "shell.execute_reply": "2024-09-16T09:26:24.77822Z",
     "shell.execute_reply.started": "2024-09-16T09:26:24.77244Z"
    },
    "id": "Hz0ZdQ_fgHhG"
   },
   "outputs": [],
   "source": [
    "def retreive_dataset(set_name):\n",
    "    images,labels=[],[]\n",
    "    for (img, imclass) in zip(set_name['videoname'], set_name['label']):\n",
    "        images.append(cv2.imread('../input/deepfake-faces/faces_224/'+img[:-4]+'.jpg'))\n",
    "        if(imclass=='FAKE'):\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "    \n",
    "    return np.array(images),np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:26:24.781171Z",
     "iopub.status.busy": "2024-09-16T09:26:24.780758Z",
     "iopub.status.idle": "2024-09-16T09:28:32.574611Z",
     "shell.execute_reply": "2024-09-16T09:28:32.573634Z",
     "shell.execute_reply.started": "2024-09-16T09:26:24.781121Z"
    },
    "id": "zeAGRcAbguKU"
   },
   "outputs": [],
   "source": [
    "X_train,y_train=retreive_dataset(Train_set)\n",
    "X_val,y_val=retreive_dataset(Val_set)\n",
    "X_test,y_test=retreive_dataset(Test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:28:32.576142Z",
     "iopub.status.busy": "2024-09-16T09:28:32.575821Z",
     "iopub.status.idle": "2024-09-16T09:28:33.087987Z",
     "shell.execute_reply": "2024-09-16T09:28:33.086945Z",
     "shell.execute_reply.started": "2024-09-16T09:28:32.5761Z"
    },
    "id": "34upiak4pKz6"
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "tf.random.set_seed(42) \n",
    "DefaultConv2D = partial(tf.keras.layers.Conv2D, kernel_size=3, padding=\"same\",\n",
    "                        activation=\"relu\", kernel_initializer=\"he_normal\")\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    DefaultConv2D(filters=64, kernel_size=7, input_shape=[224, 224, 3]),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    DefaultConv2D(filters=128),\n",
    "    DefaultConv2D(filters=128),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=128, activation=\"relu\",\n",
    "                          kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(units=64, activation=\"relu\",\n",
    "                          kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(units=1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:28:33.091509Z",
     "iopub.status.busy": "2024-09-16T09:28:33.090775Z",
     "iopub.status.idle": "2024-09-16T09:28:33.134411Z",
     "shell.execute_reply": "2024-09-16T09:28:33.133423Z",
     "shell.execute_reply.started": "2024-09-16T09:28:33.09146Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:28:33.136102Z",
     "iopub.status.busy": "2024-09-16T09:28:33.135681Z",
     "iopub.status.idle": "2024-09-16T09:32:48.92199Z",
     "shell.execute_reply": "2024-09-16T09:32:48.921018Z",
     "shell.execute_reply.started": "2024-09-16T09:28:33.136058Z"
    },
    "id": "KZbWeIBYpKz6",
    "outputId": "deb6f56a-7b93-4241-a1bd-b210c0f2d426"
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=5,batch_size=64,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:32:48.923804Z",
     "iopub.status.busy": "2024-09-16T09:32:48.923461Z",
     "iopub.status.idle": "2024-09-16T09:32:59.434525Z",
     "shell.execute_reply": "2024-09-16T09:32:59.433575Z",
     "shell.execute_reply.started": "2024-09-16T09:32:48.923769Z"
    },
    "id": "6HDDr4uehast"
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:32:59.43673Z",
     "iopub.status.busy": "2024-09-16T09:32:59.436135Z",
     "iopub.status.idle": "2024-09-16T09:33:00.451242Z",
     "shell.execute_reply": "2024-09-16T09:33:00.450251Z",
     "shell.execute_reply.started": "2024-09-16T09:32:59.436693Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot model performance\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(1, len(history.epoch) + 1)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Train Set')\n",
    "plt.plot(epochs_range, val_acc, label='Val Set')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Train Set')\n",
    "plt.plot(epochs_range, val_loss, label='Val Set')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Model Loss')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A baseline score is set here around ~51%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hqxnSBJ3pKz8"
   },
   "source": [
    "# Pretrained Models for Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using Xception model for fine-tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:33:00.453706Z",
     "iopub.status.busy": "2024-09-16T09:33:00.45278Z",
     "iopub.status.idle": "2024-09-16T09:33:05.821683Z",
     "shell.execute_reply": "2024-09-16T09:33:05.820551Z",
     "shell.execute_reply.started": "2024-09-16T09:33:00.453654Z"
    }
   },
   "outputs": [],
   "source": [
    "train_set_raw=tf.data.Dataset.from_tensor_slices((X_train,y_train))\n",
    "valid_set_raw=tf.data.Dataset.from_tensor_slices((X_val,y_val))\n",
    "test_set_raw=tf.data.Dataset.from_tensor_slices((X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:33:05.82367Z",
     "iopub.status.busy": "2024-09-16T09:33:05.82326Z",
     "iopub.status.idle": "2024-09-16T09:33:07.545096Z",
     "shell.execute_reply": "2024-09-16T09:33:07.544322Z",
     "shell.execute_reply.started": "2024-09-16T09:33:05.823624Z"
    },
    "id": "Bnz0n9XApKz9"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()  # extra code – resets layer name counter\n",
    "\n",
    "batch_size = 32\n",
    "preprocess = tf.keras.applications.xception.preprocess_input\n",
    "train_set = train_set_raw.map(lambda X, y: (preprocess(tf.cast(X, tf.float32)), y))\n",
    "train_set = train_set.shuffle(1000, seed=42).batch(batch_size).prefetch(1)\n",
    "valid_set = valid_set_raw.map(lambda X, y: (preprocess(tf.cast(X, tf.float32)), y)).batch(batch_size)\n",
    "test_set = test_set_raw.map(lambda X, y: (preprocess(tf.cast(X, tf.float32)), y)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:33:07.546523Z",
     "iopub.status.busy": "2024-09-16T09:33:07.546175Z",
     "iopub.status.idle": "2024-09-16T09:33:09.232216Z",
     "shell.execute_reply": "2024-09-16T09:33:09.231077Z",
     "shell.execute_reply.started": "2024-09-16T09:33:07.546489Z"
    },
    "id": "ZL3c3i4opKz9",
    "outputId": "38847d8d-8822-41a3-cfb2-27479aa5debe"
   },
   "outputs": [],
   "source": [
    "# extra code – displays the first 9 images in the first batch of valid_set\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "for X_batch, y_batch in valid_set.take(1):\n",
    "    for index in range(9):\n",
    "        plt.subplot(3, 3, index + 1)\n",
    "        plt.imshow((X_batch[index] + 1) / 2)  # rescale to 0–1 for imshow()\n",
    "        if(y_batch[index]==1):\n",
    "            classt='FAKE'\n",
    "        else:\n",
    "            classt='REAL'\n",
    "        plt.title(f\"Class: {classt}\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:33:09.233972Z",
     "iopub.status.busy": "2024-09-16T09:33:09.23359Z",
     "iopub.status.idle": "2024-09-16T09:33:09.257171Z",
     "shell.execute_reply": "2024-09-16T09:33:09.256041Z",
     "shell.execute_reply.started": "2024-09-16T09:33:09.233931Z"
    },
    "id": "Ib0cA8Y1pKz9"
   },
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(mode=\"horizontal\", seed=42),\n",
    "    tf.keras.layers.RandomRotation(factor=0.05, seed=42),\n",
    "    tf.keras.layers.RandomContrast(factor=0.2, seed=42)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:33:09.259533Z",
     "iopub.status.busy": "2024-09-16T09:33:09.258737Z",
     "iopub.status.idle": "2024-09-16T09:33:12.509102Z",
     "shell.execute_reply": "2024-09-16T09:33:12.508052Z",
     "shell.execute_reply.started": "2024-09-16T09:33:09.259484Z"
    },
    "id": "w6GH5_vupKz-",
    "outputId": "eeb2c924-2f4f-4aa1-bea9-951bebef4bf0"
   },
   "outputs": [],
   "source": [
    "# extra code – displays the same first 9 images, after augmentation\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "for X_batch, y_batch in valid_set.take(1):\n",
    "    X_batch_augmented = data_augmentation(X_batch, training=True)\n",
    "    for index in range(9):\n",
    "        plt.subplot(3, 3, index + 1)\n",
    "        # We must rescale the images to the 0-1 range for imshow(), and also\n",
    "        # clip the result to that range, because data augmentation may\n",
    "        # make some values go out of bounds (e.g., RandomContrast in this case).\n",
    "        plt.imshow(np.clip((X_batch_augmented[index] + 1) / 2, 0, 1))\n",
    "        if(y_batch[index]==1):\n",
    "            classt='FAKE'\n",
    "        else:\n",
    "            classt='REAL'\n",
    "        plt.title(f\"Class: {classt}\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:33:12.510759Z",
     "iopub.status.busy": "2024-09-16T09:33:12.510457Z",
     "iopub.status.idle": "2024-09-16T09:33:14.418806Z",
     "shell.execute_reply": "2024-09-16T09:33:14.417879Z",
     "shell.execute_reply.started": "2024-09-16T09:33:12.510727Z"
    },
    "id": "lRyCgvaKpKz-",
    "outputId": "a825e173-8b1d-4217-a1c4-5491b49c3e82"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)  # extra code – ensures reproducibility\n",
    "base_model = tf.keras.applications.xception.Xception(weights=\"imagenet\",\n",
    "                                                     include_top=False)\n",
    "avg = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(avg)\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:33:14.420307Z",
     "iopub.status.busy": "2024-09-16T09:33:14.419978Z",
     "iopub.status.idle": "2024-09-16T09:33:14.428509Z",
     "shell.execute_reply": "2024-09-16T09:33:14.427484Z",
     "shell.execute_reply.started": "2024-09-16T09:33:14.420274Z"
    },
    "id": "KBlyG6ElpKz-"
   },
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:33:14.430113Z",
     "iopub.status.busy": "2024-09-16T09:33:14.429815Z",
     "iopub.status.idle": "2024-09-16T09:36:24.628366Z",
     "shell.execute_reply": "2024-09-16T09:36:24.62725Z",
     "shell.execute_reply.started": "2024-09-16T09:33:14.430082Z"
    },
    "id": "GGxK2yPcpKz-",
    "outputId": "6b64214a-e104-4b6c-9b7a-3388fc9aa15f"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit(train_set, validation_data=valid_set, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:36:24.630779Z",
     "iopub.status.busy": "2024-09-16T09:36:24.629959Z",
     "iopub.status.idle": "2024-09-16T09:36:24.650691Z",
     "shell.execute_reply": "2024-09-16T09:36:24.649603Z",
     "shell.execute_reply.started": "2024-09-16T09:36:24.630728Z"
    },
    "id": "GvGMiJMLpKz-",
    "outputId": "91f2c96c-c058-45e0-e428-66fa6076ad56"
   },
   "outputs": [],
   "source": [
    "for indices in zip(range(33), range(33, 66), range(66, 99), range(99, 132)):\n",
    "    for idx in indices:\n",
    "        print(f\"{idx:3}: {base_model.layers[idx].name:22}\", end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:36:24.652275Z",
     "iopub.status.busy": "2024-09-16T09:36:24.651891Z",
     "iopub.status.idle": "2024-09-16T09:36:39.117594Z",
     "shell.execute_reply": "2024-09-16T09:36:39.116418Z",
     "shell.execute_reply.started": "2024-09-16T09:36:24.652239Z"
    }
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After Fine tuning The accuracy comes about ~64%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L_bEwL8KpKz_"
   },
   "source": [
    "Now that the weights of our new top layers are not too bad, we can make the top part of the base model trainable again, and continue training, but with a lower learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:36:39.119009Z",
     "iopub.status.busy": "2024-09-16T09:36:39.118705Z",
     "iopub.status.idle": "2024-09-16T09:54:48.567589Z",
     "shell.execute_reply": "2024-09-16T09:54:48.566699Z",
     "shell.execute_reply.started": "2024-09-16T09:36:39.118978Z"
    },
    "id": "GEUNGlhvpKz_",
    "outputId": "c622a91d-f634-4443-b87e-8d46defdb578"
   },
   "outputs": [],
   "source": [
    "for layer in base_model.layers[56:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit(train_set, validation_data=valid_set, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:54:48.56915Z",
     "iopub.status.busy": "2024-09-16T09:54:48.568818Z",
     "iopub.status.idle": "2024-09-16T09:54:49.106627Z",
     "shell.execute_reply": "2024-09-16T09:54:49.105624Z",
     "shell.execute_reply.started": "2024-09-16T09:54:48.569116Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot model performance\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(1, len(history.epoch) + 1)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Train Set')\n",
    "plt.plot(epochs_range, val_acc, label='Val Set')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Train Set')\n",
    "plt.plot(epochs_range, val_loss, label='Val Set')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Model Loss')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:54:49.10858Z",
     "iopub.status.busy": "2024-09-16T09:54:49.108233Z",
     "iopub.status.idle": "2024-09-16T09:55:03.34428Z",
     "shell.execute_reply": "2024-09-16T09:55:03.343404Z",
     "shell.execute_reply.started": "2024-09-16T09:54:49.108545Z"
    }
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The model accuracy finally reaches to 81.9%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:55:03.345786Z",
     "iopub.status.busy": "2024-09-16T09:55:03.345469Z",
     "iopub.status.idle": "2024-09-16T09:55:03.991138Z",
     "shell.execute_reply": "2024-09-16T09:55:03.990125Z",
     "shell.execute_reply.started": "2024-09-16T09:55:03.345753Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('xception_deepfake_image.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Explainability to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:55:03.992962Z",
     "iopub.status.busy": "2024-09-16T09:55:03.992618Z",
     "iopub.status.idle": "2024-09-16T09:55:17.924061Z",
     "shell.execute_reply": "2024-09-16T09:55:17.922975Z",
     "shell.execute_reply.started": "2024-09-16T09:55:03.992926Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:55:17.925957Z",
     "iopub.status.busy": "2024-09-16T09:55:17.925618Z",
     "iopub.status.idle": "2024-09-16T09:55:18.83805Z",
     "shell.execute_reply": "2024-09-16T09:55:18.837192Z",
     "shell.execute_reply.started": "2024-09-16T09:55:17.925919Z"
    }
   },
   "outputs": [],
   "source": [
    "from lime import lime_image\n",
    "\n",
    "explainer = lime_image.LimeImageExplainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:55:18.840875Z",
     "iopub.status.busy": "2024-09-16T09:55:18.839359Z",
     "iopub.status.idle": "2024-09-16T09:55:19.92841Z",
     "shell.execute_reply": "2024-09-16T09:55:19.923986Z",
     "shell.execute_reply.started": "2024-09-16T09:55:18.84083Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "for index in range(9):\n",
    "    plt.subplot(3, 3, index + 1)\n",
    "    plt.imshow((x[index] + 1) / 2)  # rescale to 0–1 for imshow()\n",
    "    if(y[index]==1):\n",
    "        classt='FAKE'\n",
    "    else:\n",
    "        classt='REAL'\n",
    "    plt.title(f\"Class: {classt}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-16T09:55:19.929454Z",
     "iopub.status.idle": "2024-09-16T09:55:19.929894Z",
     "shell.execute_reply": "2024-09-16T09:55:19.929694Z",
     "shell.execute_reply.started": "2024-09-16T09:55:19.929673Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data=x[2,:,:,:]\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-16T09:55:19.931253Z",
     "iopub.status.idle": "2024-09-16T09:55:19.931694Z",
     "shell.execute_reply": "2024-09-16T09:55:19.931508Z",
     "shell.execute_reply.started": "2024-09-16T09:55:19.931486Z"
    }
   },
   "outputs": [],
   "source": [
    "explanation = explainer.explain_instance(test_data.astype('double'), model.predict,  \n",
    "                                         top_labels=3, hide_color=0, num_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-16T09:55:19.933633Z",
     "iopub.status.idle": "2024-09-16T09:55:19.934056Z",
     "shell.execute_reply": "2024-09-16T09:55:19.933869Z",
     "shell.execute_reply.started": "2024-09-16T09:55:19.933849Z"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.segmentation import mark_boundaries\n",
    "\n",
    "temp_1, mask_1 = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=True)\n",
    "temp_2, mask_2 = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=10, hide_rest=False)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,15))\n",
    "ax1.imshow(mark_boundaries(temp_1, mask_1))\n",
    "ax2.imshow(mark_boundaries(temp_2, mask_2))\n",
    "ax1.axis('off')\n",
    "ax2.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Fake Video Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-16T09:55:19.936177Z",
     "iopub.status.idle": "2024-09-16T09:55:19.936644Z",
     "shell.execute_reply": "2024-09-16T09:55:19.936446Z",
     "shell.execute_reply.started": "2024-09-16T09:55:19.936426Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -U --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T10:09:49.362397Z",
     "iopub.status.busy": "2024-09-16T10:09:49.361652Z",
     "iopub.status.idle": "2024-09-16T10:09:49.449111Z",
     "shell.execute_reply": "2024-09-16T10:09:49.44819Z",
     "shell.execute_reply.started": "2024-09-16T10:09:49.362356Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow import keras\n",
    "#from imutils import paths\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:58:04.948691Z",
     "iopub.status.busy": "2024-09-16T09:58:04.947759Z",
     "iopub.status.idle": "2024-09-16T09:58:04.958932Z",
     "shell.execute_reply": "2024-09-16T09:58:04.957867Z",
     "shell.execute_reply.started": "2024-09-16T09:58:04.948645Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = '../input/deepfake-detection-challenge'\n",
    "TRAIN_SAMPLE_FOLDER = 'train_sample_videos'\n",
    "TEST_FOLDER = 'test_videos'\n",
    "\n",
    "print(f\"Train samples: {len(os.listdir(os.path.join(DATA_FOLDER, TRAIN_SAMPLE_FOLDER)))}\")\n",
    "print(f\"Test samples: {len(os.listdir(os.path.join(DATA_FOLDER, TEST_FOLDER)))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:58:08.193152Z",
     "iopub.status.busy": "2024-09-16T09:58:08.19239Z",
     "iopub.status.idle": "2024-09-16T09:58:08.326297Z",
     "shell.execute_reply": "2024-09-16T09:58:08.325238Z",
     "shell.execute_reply.started": "2024-09-16T09:58:08.1931Z"
    }
   },
   "outputs": [],
   "source": [
    "train_sample_metadata = pd.read_json('../input/deepfake-detection-challenge/train_sample_videos/metadata.json').T\n",
    "train_sample_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:58:13.707876Z",
     "iopub.status.busy": "2024-09-16T09:58:13.706923Z",
     "iopub.status.idle": "2024-09-16T09:58:14.036375Z",
     "shell.execute_reply": "2024-09-16T09:58:14.035268Z",
     "shell.execute_reply.started": "2024-09-16T09:58:13.707825Z"
    }
   },
   "outputs": [],
   "source": [
    "train_sample_metadata.groupby('label')['label'].count().plot(figsize=(15, 5), kind='bar', title='Distribution of Labels in the Training Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:58:17.967074Z",
     "iopub.status.busy": "2024-09-16T09:58:17.966692Z",
     "iopub.status.idle": "2024-09-16T09:58:17.973517Z",
     "shell.execute_reply": "2024-09-16T09:58:17.972564Z",
     "shell.execute_reply.started": "2024-09-16T09:58:17.967041Z"
    }
   },
   "outputs": [],
   "source": [
    "train_sample_metadata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fake videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:58:23.777974Z",
     "iopub.status.busy": "2024-09-16T09:58:23.777041Z",
     "iopub.status.idle": "2024-09-16T09:58:23.786451Z",
     "shell.execute_reply": "2024-09-16T09:58:23.785356Z",
     "shell.execute_reply.started": "2024-09-16T09:58:23.777929Z"
    }
   },
   "outputs": [],
   "source": [
    "fake_train_sample_video = list(train_sample_metadata.loc[train_sample_metadata.label=='FAKE'].sample(3).index)\n",
    "fake_train_sample_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:58:26.42789Z",
     "iopub.status.busy": "2024-09-16T09:58:26.427161Z",
     "iopub.status.idle": "2024-09-16T09:58:26.43345Z",
     "shell.execute_reply": "2024-09-16T09:58:26.432364Z",
     "shell.execute_reply.started": "2024-09-16T09:58:26.427848Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_image_from_video(video_path):\n",
    "    capture_image = cv2.VideoCapture(video_path) \n",
    "    ret, frame = capture_image.read()\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    ax.imshow(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:58:38.723396Z",
     "iopub.status.busy": "2024-09-16T09:58:38.72248Z",
     "iopub.status.idle": "2024-09-16T09:58:42.098363Z",
     "shell.execute_reply": "2024-09-16T09:58:42.097367Z",
     "shell.execute_reply.started": "2024-09-16T09:58:38.723348Z"
    }
   },
   "outputs": [],
   "source": [
    "for video_file in fake_train_sample_video:\n",
    "    display_image_from_video(os.path.join(DATA_FOLDER, TRAIN_SAMPLE_FOLDER, video_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:58:57.247648Z",
     "iopub.status.busy": "2024-09-16T09:58:57.247236Z",
     "iopub.status.idle": "2024-09-16T09:58:57.256623Z",
     "shell.execute_reply": "2024-09-16T09:58:57.255397Z",
     "shell.execute_reply.started": "2024-09-16T09:58:57.247609Z"
    }
   },
   "outputs": [],
   "source": [
    "real_train_sample_video = list(train_sample_metadata.loc[train_sample_metadata.label=='REAL'].sample(3).index)\n",
    "real_train_sample_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:59:05.782908Z",
     "iopub.status.busy": "2024-09-16T09:59:05.782545Z",
     "iopub.status.idle": "2024-09-16T09:59:08.476563Z",
     "shell.execute_reply": "2024-09-16T09:59:08.475483Z",
     "shell.execute_reply.started": "2024-09-16T09:59:05.782875Z"
    }
   },
   "outputs": [],
   "source": [
    "for video_file in real_train_sample_video:\n",
    "    display_image_from_video(os.path.join(DATA_FOLDER, TRAIN_SAMPLE_FOLDER, video_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Videos with same original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:59:21.113354Z",
     "iopub.status.busy": "2024-09-16T09:59:21.112441Z",
     "iopub.status.idle": "2024-09-16T09:59:21.131358Z",
     "shell.execute_reply": "2024-09-16T09:59:21.130256Z",
     "shell.execute_reply.started": "2024-09-16T09:59:21.113312Z"
    }
   },
   "outputs": [],
   "source": [
    "train_sample_metadata['original'].value_counts()[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pick one of the originals with largest number of samples.\n",
    "\n",
    "We also modify our visualization function to work with multiple images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:59:15.828032Z",
     "iopub.status.busy": "2024-09-16T09:59:15.826966Z",
     "iopub.status.idle": "2024-09-16T09:59:15.837857Z",
     "shell.execute_reply": "2024-09-16T09:59:15.836647Z",
     "shell.execute_reply.started": "2024-09-16T09:59:15.827974Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_image_from_video_list(video_path_list, video_folder=TRAIN_SAMPLE_FOLDER):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(2,3,figsize=(16,8))\n",
    "    # we only show images extracted from the first 6 videos\n",
    "    for i, video_file in enumerate(video_path_list[0:6]):\n",
    "        video_path = os.path.join(DATA_FOLDER, video_folder,video_file)\n",
    "        capture_image = cv2.VideoCapture(video_path) \n",
    "        ret, frame = capture_image.read()\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        ax[i//3, i%3].imshow(frame)\n",
    "        ax[i//3, i%3].set_title(f\"Video: {video_file}\")\n",
    "        ax[i//3, i%3].axis('on')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:59:41.288368Z",
     "iopub.status.busy": "2024-09-16T09:59:41.287308Z",
     "iopub.status.idle": "2024-09-16T09:59:45.266253Z",
     "shell.execute_reply": "2024-09-16T09:59:45.265248Z",
     "shell.execute_reply.started": "2024-09-16T09:59:41.288318Z"
    }
   },
   "outputs": [],
   "source": [
    "same_original_fake_train_sample_video = list(train_sample_metadata.loc[train_sample_metadata.original=='atvmxvwyns.mp4'].index)\n",
    "display_image_from_video_list(same_original_fake_train_sample_video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test video files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:59:52.593716Z",
     "iopub.status.busy": "2024-09-16T09:59:52.592672Z",
     "iopub.status.idle": "2024-09-16T09:59:52.603533Z",
     "shell.execute_reply": "2024-09-16T09:59:52.602518Z",
     "shell.execute_reply.started": "2024-09-16T09:59:52.59367Z"
    }
   },
   "outputs": [],
   "source": [
    "test_videos = pd.DataFrame(list(os.listdir(os.path.join(DATA_FOLDER, TEST_FOLDER))), columns=['video'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:59:59.312548Z",
     "iopub.status.busy": "2024-09-16T09:59:59.312092Z",
     "iopub.status.idle": "2024-09-16T09:59:59.322216Z",
     "shell.execute_reply": "2024-09-16T09:59:59.321107Z",
     "shell.execute_reply.started": "2024-09-16T09:59:59.312508Z"
    }
   },
   "outputs": [],
   "source": [
    "test_videos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visual of a videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T10:00:02.472652Z",
     "iopub.status.busy": "2024-09-16T10:00:02.471902Z",
     "iopub.status.idle": "2024-09-16T10:00:03.417509Z",
     "shell.execute_reply": "2024-09-16T10:00:03.416452Z",
     "shell.execute_reply.started": "2024-09-16T10:00:02.472606Z"
    }
   },
   "outputs": [],
   "source": [
    "display_image_from_video(os.path.join(DATA_FOLDER, TEST_FOLDER, test_videos.iloc[2].video))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play video files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T10:00:11.153055Z",
     "iopub.status.busy": "2024-09-16T10:00:11.152268Z",
     "iopub.status.idle": "2024-09-16T10:00:11.1588Z",
     "shell.execute_reply": "2024-09-16T10:00:11.157706Z",
     "shell.execute_reply.started": "2024-09-16T10:00:11.153014Z"
    }
   },
   "outputs": [],
   "source": [
    "fake_videos = list(train_sample_metadata.loc[train_sample_metadata.label=='FAKE'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T10:00:17.56756Z",
     "iopub.status.busy": "2024-09-16T10:00:17.566751Z",
     "iopub.status.idle": "2024-09-16T10:00:17.839066Z",
     "shell.execute_reply": "2024-09-16T10:00:17.837603Z",
     "shell.execute_reply.started": "2024-09-16T10:00:17.567519Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "def play_video(video_file, subset=TRAIN_SAMPLE_FOLDER):\n",
    "    video_url = open(os.path.join(DATA_FOLDER, subset,video_file),'rb').read()\n",
    "    data_url = \"data:video/mp4;base64,\" + b64encode(video_url).decode()\n",
    "    return HTML(\"\"\"<video width=500 controls><source src=\"%s\" type=\"video/mp4\"></video>\"\"\" % data_url)\n",
    "\n",
    "play_video(fake_videos[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A CNN-RNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T10:12:13.360704Z",
     "iopub.status.busy": "2024-09-16T10:12:13.359904Z",
     "iopub.status.idle": "2024-09-16T10:12:13.366097Z",
     "shell.execute_reply": "2024-09-16T10:12:13.364965Z",
     "shell.execute_reply.started": "2024-09-16T10:12:13.360651Z"
    }
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "\n",
    "MAX_SEQ_LENGTH = 20\n",
    "NUM_FEATURES = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T10:00:51.232754Z",
     "iopub.status.busy": "2024-09-16T10:00:51.231904Z",
     "iopub.status.idle": "2024-09-16T10:00:51.242443Z",
     "shell.execute_reply": "2024-09-16T10:00:51.241446Z",
     "shell.execute_reply.started": "2024-09-16T10:00:51.232703Z"
    }
   },
   "outputs": [],
   "source": [
    "def crop_center_square(frame):\n",
    "    y, x = frame.shape[0:2]\n",
    "    min_dim = min(y, x)\n",
    "    start_x = (x // 2) - (min_dim // 2)\n",
    "    start_y = (y // 2) - (min_dim // 2)\n",
    "    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]\n",
    "\n",
    "\n",
    "def load_video(path, max_frames=0, resize=(IMG_SIZE, IMG_SIZE)):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = crop_center_square(frame)\n",
    "            frame = cv2.resize(frame, resize)\n",
    "            frame = frame[:, :, [2, 1, 0]]\n",
    "            frames.append(frame)\n",
    "\n",
    "            if len(frames) == max_frames:\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "    return np.array(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using the InceptionV3 model to extract meaningful features from the extracted frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T10:01:27.133488Z",
     "iopub.status.busy": "2024-09-16T10:01:27.132676Z",
     "iopub.status.idle": "2024-09-16T10:01:29.835813Z",
     "shell.execute_reply": "2024-09-16T10:01:29.834745Z",
     "shell.execute_reply.started": "2024-09-16T10:01:27.133439Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "def build_feature_extractor():\n",
    "    feature_extractor = keras.applications.InceptionV3(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        pooling=\"avg\",\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    )\n",
    "    preprocess_input = keras.applications.inception_v3.preprocess_input\n",
    "\n",
    "    inputs = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
    "    preprocessed = preprocess_input(inputs)\n",
    "\n",
    "    outputs = feature_extractor(preprocessed)\n",
    "    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n",
    "\n",
    "\n",
    "feature_extractor = build_feature_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T10:05:29.177557Z",
     "iopub.status.busy": "2024-09-16T10:05:29.177075Z",
     "iopub.status.idle": "2024-09-16T10:05:29.189111Z",
     "shell.execute_reply": "2024-09-16T10:05:29.187941Z",
     "shell.execute_reply.started": "2024-09-16T10:05:29.177515Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_all_videos(df, root_dir):\n",
    "    num_samples = len(df)\n",
    "    video_paths = list(df.index)\n",
    "    labels = df[\"label\"].values\n",
    "    labels = np.array(labels=='FAKE').astype(int)\n",
    "\n",
    "    # `frame_masks` and `frame_features` are what we will feed to our sequence model.\n",
    "    # `frame_masks` will contain a bunch of booleans denoting if a timestep is\n",
    "    # masked with padding or not.\n",
    "    frame_masks = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH), dtype=\"bool\")\n",
    "    frame_features = np.zeros(\n",
    "        shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
    "    )\n",
    "\n",
    "    # For each video.\n",
    "    for idx, path in enumerate(video_paths):\n",
    "        # Gather all its frames and add a batch dimension.\n",
    "        frames = load_video(os.path.join(root_dir, path))\n",
    "        frames = frames[None, ...]\n",
    "\n",
    "        # Initialize placeholders to store the masks and features of the current video.\n",
    "        temp_frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "        temp_frame_features = np.zeros(\n",
    "            shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
    "        )\n",
    "\n",
    "        # Extract features from the frames of the current video.\n",
    "        for i, batch in enumerate(frames):\n",
    "            video_length = batch.shape[0]\n",
    "            length = min(MAX_SEQ_LENGTH, video_length)\n",
    "            for j in range(length):\n",
    "                temp_frame_features[i, j, :] = feature_extractor.predict(\n",
    "                    batch[None, j, :]\n",
    "                )\n",
    "            temp_frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
    "\n",
    "        frame_features[idx,] = temp_frame_features.squeeze()\n",
    "        frame_masks[idx,] = temp_frame_mask.squeeze()\n",
    "\n",
    "    return (frame_features, frame_masks), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T10:05:34.807317Z",
     "iopub.status.busy": "2024-09-16T10:05:34.806802Z",
     "iopub.status.idle": "2024-09-16T10:05:34.81871Z",
     "shell.execute_reply": "2024-09-16T10:05:34.816809Z",
     "shell.execute_reply.started": "2024-09-16T10:05:34.807269Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Train_set, Test_set = train_test_split(train_sample_metadata,test_size=0.1,random_state=42,stratify=train_sample_metadata['label'])\n",
    "\n",
    "print(Train_set.shape, Test_set.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels = prepare_all_videos(Train_set, \"train\")\n",
    "test_data, test_labels = prepare_all_videos(Test_set, \"test\")\n",
    "\n",
    "print(f\"Frame features in train set: {train_data[0].shape}\")\n",
    "print(f\"Frame masks in train set: {train_data[1].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The sequence model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T10:14:25.51383Z",
     "iopub.status.busy": "2024-09-16T10:14:25.512868Z",
     "iopub.status.idle": "2024-09-16T10:14:25.601745Z",
     "shell.execute_reply": "2024-09-16T10:14:25.600875Z",
     "shell.execute_reply.started": "2024-09-16T10:14:25.513788Z"
    }
   },
   "outputs": [],
   "source": [
    "frame_features_input = keras.Input((MAX_SEQ_LENGTH, NUM_FEATURES))\n",
    "mask_input = keras.Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "\n",
    "#can use LSTM as well\n",
    "x = keras.layers.GRU(16, return_sequences=True)(\n",
    "    frame_features_input, mask=mask_input\n",
    ")\n",
    "x = keras.layers.GRU(8)(x)\n",
    "x = keras.layers.Dropout(0.4)(x)\n",
    "x = keras.layers.Dense(8, activation=\"relu\")(x)\n",
    "output = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = keras.Model([frame_features_input, mask_input], output)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T10:14:34.53267Z",
     "iopub.status.busy": "2024-09-16T10:14:34.532241Z",
     "iopub.status.idle": "2024-09-16T10:14:34.537692Z",
     "shell.execute_reply": "2024-09-16T10:14:34.536551Z",
     "shell.execute_reply.started": "2024-09-16T10:14:34.532632Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T10:14:42.177899Z",
     "iopub.status.busy": "2024-09-16T10:14:42.17746Z",
     "iopub.status.idle": "2024-09-16T10:14:44.455792Z",
     "shell.execute_reply": "2024-09-16T10:14:44.454337Z",
     "shell.execute_reply.started": "2024-09-16T10:14:42.17786Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = keras.callbacks.ModelCheckpoint('./inceptionV3.weights.h5', save_weights_only=True, save_best_only=True)\n",
    "history = model.fit(\n",
    "        [train_data[0], train_data[1]],\n",
    "        train_labels,\n",
    "        validation_data=([test_data[0], test_data[1]],test_labels),\n",
    "        callbacks=[checkpoint],\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=4\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The deep fake image classifier and deep fake video classifier model gave a generalisation error of around ~82%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://keras.io/examples/vision/video_classification/\n",
    "\n",
    "https://www.kaggle.com/code/gpreda/deepfake-starter-kit\n",
    "\n",
    "https://www.kaggle.com/code/robikscube/kaggle-deepfake-detection-introduction\n",
    "\n",
    "https://www.kaggle.com/code/humananalog/binary-image-classifier-training-demo\n",
    "\n",
    "https://www.kaggle.com/datasets/dagnelies/deepfake-faces\n",
    "\n",
    "https://www.kaggle.com/code/gautam20bce1227/fake-detection-on-images"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 858837,
     "sourceId": 16880,
     "sourceType": "competition"
    },
    {
     "datasetId": 464091,
     "sourceId": 924245,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
